{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "import collections\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "import sys\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hi.', 'Hallo!'], ['Hi.', 'Grüß Gott!']]\n",
      "['Hi.\\tHallo!', 'Hi.\\tGrüß Gott!']\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "all_lines=[]\n",
    "\n",
    "fptr = open('deu.txt', 'r', encoding='utf-8')\n",
    "# read all text\n",
    "lines = fptr.readlines()\n",
    "#print(lines)\n",
    "for line in lines :\n",
    "    #print(line)\n",
    "    line=line.strip()\n",
    "    k = line.split('\\t')\n",
    "    \n",
    "    all_lines.append(line)\n",
    "    pairs.append(k)\n",
    "print(pairs[0:2])\n",
    "print(all_lines[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng_length = 0\n",
    "max_ger_length = 0\n",
    "\n",
    "cleaned = list()\n",
    "# prepare regex for char filtering\n",
    "re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "# prepare translation table for removing punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for pair in pairs:\n",
    "    #print(pair[0])\n",
    "    \n",
    "        \n",
    "    clean_pair = list()\n",
    "    for line in pair:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "        # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        # store as string\n",
    "        clean_pair.append(' '.join(line))\n",
    "    cleaned.append(clean_pair)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi => hallo\n",
      "hi => gru gott\n"
     ]
    }
   ],
   "source": [
    "print(cleaned[0][0] + \" => \" + cleaned[0][1])\n",
    "print(cleaned[1][0] + \" => \" + cleaned[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi', 'hallo'], ['hi', 'gru gott']]\n",
      "10000\n",
      "['hi', 'hallo']\n",
      "['hi', 'gru gott']\n"
     ]
    }
   ],
   "source": [
    "# reduce dataset size\n",
    "n_sentences = 10000\n",
    "dataset = cleaned[:n_sentences]\n",
    "print(dataset[0:2])\n",
    "print(len(dataset))\n",
    "print(dataset[0:2][0])\n",
    "print(dataset[0:2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'hallo']\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "max_eng_length = 0\n",
    "max_ger_length = 0\n",
    "\n",
    "for i in range(len(dataset)) :\n",
    "    if(len(dataset[i][0]) > max_eng_length) :\n",
    "        max_eng_length = len(dataset[i][0])\n",
    "    if(len(dataset[i][1]) > max_ger_length) :\n",
    "        max_ger_length = len(dataset[i][1])\n",
    "        \n",
    "print(max_eng_length)\n",
    "print(max_ger_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "gru gott\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for i in range(len(dataset)) :\n",
    "    questions.append(dataset[i][0])\n",
    "    labels.append(dataset[i][1])\n",
    "print(questions[1])\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_data(que, lab):\n",
    "    # Preprocess\n",
    "    qs = []\n",
    "    lb = []\n",
    "\n",
    "    # to the lower case\n",
    "    for i in que :\n",
    "        i=i.lower()\n",
    "        qs.append(i)\n",
    "    for j in lab :\n",
    "        j=j.lower()\n",
    "        lb.append(j)\n",
    "\n",
    "    # create lookup tables for English and French data\n",
    "    CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "    source_vocab = []\n",
    "    target_vocab = []\n",
    "    \n",
    "    for q in qs :\n",
    "        for j in q.split() :\n",
    "            source_vocab.append(j)\n",
    "            \n",
    "    source_vocab = set(source_vocab)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for l in lb :\n",
    "        for k in l.split() :\n",
    "            target_vocab.append(k)\n",
    "            \n",
    "    target_vocab = set(target_vocab)\n",
    "    #print(target_vocab)\n",
    "    \n",
    "    source_vocab_to_int = copy.copy(CODES)\n",
    "    for v_i, v in enumerate(source_vocab, len(CODES)):\n",
    "        source_vocab_to_int[v] = v_i\n",
    "\n",
    "\n",
    "    source_int_to_vocab = {v_i: v for v, v_i in source_vocab_to_int.items()}    \n",
    "    \n",
    "\n",
    " \n",
    "    target_vocab_to_int = copy.copy(CODES)\n",
    "    for v_i, v in enumerate(target_vocab, len(CODES)):\n",
    "        target_vocab_to_int[v] = v_i\n",
    "\n",
    "\n",
    "    target_int_to_vocab = {v_i: v for v, v_i in target_vocab_to_int.items()}\n",
    "    \n",
    "    \n",
    "\n",
    "    # create list of sentences whose words are represented in index\n",
    "    \n",
    "    source_text = []\n",
    "    target_text = []\n",
    "    \n",
    "    for q in qs :\n",
    "        source_tokens = q.split(\" \")\n",
    "        \n",
    "        # empty list of converted words to index in the chosen sentence\n",
    "        source_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(source_tokens):\n",
    "            if (token != \"\"):\n",
    "                source_token_id.append(source_vocab_to_int[token])\n",
    "\n",
    "        source_text.append(source_token_id)        \n",
    "\n",
    "    for l in lb :\n",
    "        target_tokens = l.split(\" \")\n",
    "        \n",
    "        # empty list of converted words to index in the chosen sentence\n",
    "        target_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(target_tokens):\n",
    "            if (token != \"\"):\n",
    "                target_token_id.append(target_vocab_to_int[token])\n",
    "       \n",
    "                \n",
    "        # put <EOS> token at the end of the chosen target sentence\n",
    "        # this token suggests when to stop creating a sequence\n",
    "        target_token_id.append(target_vocab_to_int['<EOS>'])        \n",
    "        \n",
    "        target_text.append(target_token_id) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (source_text, target_text),(source_vocab_to_int, target_vocab_to_int),(source_int_to_vocab, target_int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[845], [845]]\n",
      "[[3113, 1], [3454, 463, 1]]\n"
     ]
    }
   ],
   "source": [
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab,target_int_to_vocab) = preprocess_and_save_data(questions,labels)\n",
    "\n",
    "print(source_int_text[0:2])\n",
    "print(target_int_text[0:2])\n",
    "#print(target_int_to_vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec_model_inputs():\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets') \n",
    "    \n",
    "    target_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n",
    "    max_target_len = tf.reduce_max(target_sequence_length)    \n",
    "    \n",
    "    return inputs, targets, target_sequence_length, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_inputs():\n",
    "    lr_rate = tf.placeholder(tf.float32, name='lr_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return lr_rate, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_decoder_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for encoding\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    # get '<GO>' id\n",
    "    go_id = target_vocab_to_int['<GO>']\n",
    "    \n",
    "    after_slice = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    after_concat = tf.concat( [tf.fill([batch_size, 1], go_id), after_slice], 1)\n",
    "    \n",
    "    return after_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\n",
    "\n",
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, \n",
    "                   source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "    \"\"\"\n",
    "    :return: tuple (RNN output, RNN state)\n",
    "    \"\"\"\n",
    "    embed = tf.contrib.layers.embed_sequence(rnn_inputs, \n",
    "                                             vocab_size=source_vocab_size, \n",
    "                                             embed_dim=encoding_embedding_size)\n",
    "    \n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(rnn_size), keep_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    '''((encoder_fw_outputs,\n",
    "              encoder_bw_outputs),\n",
    "             (encoder_fw_state,\n",
    "              encoder_bw_state)) = (\n",
    "                tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked_cells,\n",
    "                                                cell_bw=stacked_cells,\n",
    "                                                inputs = embed,\n",
    "                                                time_major=True,\n",
    "                                                dtype=tf.float32)\n",
    "                )'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    encoder_outputs_fw_bw, encoder_last_state_fw_bw = tf.nn.bidirectional_dynamic_rnn(\n",
    "    cell_fw=stacked_cells,\n",
    "    cell_bw=stacked_cells,\n",
    "    inputs=embed,\n",
    "    dtype=tf.float32,\n",
    "    time_major=False)\n",
    "    \n",
    "    encoder_outputs_fw, encoder_outputs_bw = encoder_outputs_fw_bw\n",
    "    encoder_outputs = tf.concat([encoder_outputs_fw, encoder_outputs_bw], 2)\n",
    "\n",
    "    encoder_last_state_fw, encoder_last_state_bw = encoder_last_state_fw_bw\n",
    "\n",
    "    encoder_last_state_zipped = zip(encoder_last_state_fw, encoder_last_state_bw)\n",
    "    encoder_last_state_list = [LSTMStateTuple(c=tf.concat([fw.c, bw.c], 1), h=tf.concat([fw.h, bw.h], 1))\n",
    "                               for fw, bw in encoder_last_state_zipped]\n",
    "    encoder_last_state = tuple(encoder_last_state_list)\n",
    "\n",
    "    \n",
    "    '''print(encoder_fw_outputs)\n",
    "    print(\"#############\")\n",
    "    print(encoder_fw_state)\n",
    "    print(\"#############\")\n",
    "    print(encoder_bw_state)\n",
    "    print(\"#############\")\n",
    "    #enc_state = tf.Variable([64,128])\n",
    "    #encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), axis = 1)\n",
    "    print(encoder_outputs)\n",
    "    print(\"#############\")\n",
    "    \n",
    "    #encoder_final_state_c = tf.concat((encoder_fw_state[0].c, encoder_bw_state[0].c), axis = 0)\n",
    "\n",
    "    #encoder_final_state_h = tf.concat((encoder_fw_state[0].h, encoder_bw_state[0].h), axis = 0)    \n",
    "    \n",
    "\n",
    "    print(encoder_final_state_c)\n",
    "    print(\"#############\")\n",
    "    \n",
    "    alternates_c = tf.map_fn(lambda x: (x, x), encoder_final_state_c, dtype=(tf.float32,tf.float32))\n",
    "    alternates_h = tf.map_fn(lambda x: (x, x), encoder_final_state_h, dtype=(tf.float32,tf.float32))  \n",
    "    encoder_final_state = LSTMStateTuple(c=encoder_final_state_c,h=encoder_final_state_h)\n",
    "    print(encoder_final_state)'''\n",
    "    \n",
    "    return encoder_outputs,encoder_last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, \n",
    "                         target_sequence_length, max_summary_length, \n",
    "                         output_layer, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a training process in decoding layer \n",
    "    :return: BasicDecoderOutput containing training logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "    \n",
    "    # for only input layer\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input, \n",
    "                                               target_sequence_length)\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, \n",
    "                                              helper, \n",
    "                                              encoder_state, \n",
    "                                              output_layer)\n",
    "\n",
    "    # unrolling the decoder layer\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True, \n",
    "                                                      maximum_iterations=max_summary_length)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id,\n",
    "                         end_of_sequence_id, max_target_sequence_length,\n",
    "                         vocab_size, output_layer, batch_size, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a inference process in decoding layer \n",
    "    :return: BasicDecoderOutput containing inference logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings, \n",
    "                                                      tf.fill([batch_size], start_of_sequence_id), \n",
    "                                                      end_of_sequence_id)\n",
    "    \n",
    "\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, \n",
    "                                              helper, \n",
    "                                              encoder_state, \n",
    "                                              output_layer)\n",
    "    \n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True, \n",
    "                                                      maximum_iterations=max_target_sequence_length)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer(dec_input, encoder_state,\n",
    "                   target_sequence_length, max_target_sequence_length,\n",
    "                   rnn_size,\n",
    "                   num_layers, target_vocab_to_int, target_vocab_size,\n",
    "                   batch_size, keep_prob, decoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    target_vocab_size = len(target_vocab_to_int)\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "    \n",
    "    cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(2*rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        output_layer = tf.layers.Dense(target_vocab_size)\n",
    "        train_output = decoding_layer_train(encoder_state, \n",
    "                                            cells, \n",
    "                                            dec_embed_input, \n",
    "                                            target_sequence_length, \n",
    "                                            max_target_sequence_length, \n",
    "                                            output_layer, \n",
    "                                            keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        infer_output = decoding_layer_infer(encoder_state, \n",
    "                                            cells, \n",
    "                                            dec_embeddings, \n",
    "                                            target_vocab_to_int['<GO>'], \n",
    "                                            target_vocab_to_int['<EOS>'], \n",
    "                                            max_target_sequence_length, \n",
    "                                            target_vocab_size, \n",
    "                                            output_layer,\n",
    "                                            batch_size,\n",
    "                                            keep_prob)\n",
    "\n",
    "    return (train_output, infer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n",
    "                  target_sequence_length,\n",
    "                  max_target_sentence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size,\n",
    "                  rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence model\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    enc_outputs, enc_states = encoding_layer(input_data, \n",
    "                                             rnn_size, \n",
    "                                             num_layers, \n",
    "                                             keep_prob, \n",
    "                                             source_vocab_size, \n",
    "                                             enc_embedding_size)\n",
    "    \n",
    "    dec_input = process_decoder_input(target_data, \n",
    "                                      target_vocab_to_int, \n",
    "                                      batch_size)\n",
    "    \n",
    "    train_output, infer_output = decoding_layer(dec_input,\n",
    "                                               enc_states, \n",
    "                                               target_sequence_length, \n",
    "                                               max_target_sentence_length,\n",
    "                                               rnn_size,\n",
    "                                              num_layers,\n",
    "                                              target_vocab_to_int,\n",
    "                                              target_vocab_size,\n",
    "                                              batch_size,\n",
    "                                              keep_prob,\n",
    "                                              dec_embedding_size)\n",
    "    \n",
    "    \n",
    "    '''print(dec_input)\n",
    "    print(\"************\")\n",
    "    print(enc_states)\n",
    "    print(\"************\")'''\n",
    "    \n",
    "    return train_output, infer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_step = 30\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "\n",
    "rnn_size = 128\n",
    "num_layers = 3\n",
    "\n",
    "encoding_embedding_size = 100\n",
    "decoding_embedding_size = 100\n",
    "\n",
    "learning_rate = 0.001\n",
    "keep_probability = 0.5\n",
    "max_grad_norm = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'checkpoints/ayan'\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab,target_int_to_vocab) = preprocess_and_save_data(questions,labels)\n",
    "max_target_sentence_length = max([len(sentence) for sentence in source_int_text])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, target_sequence_length, max_target_sequence_length = enc_dec_model_inputs()\n",
    "    lr, keep_prob = hyperparam_inputs()\n",
    "    \n",
    "    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                   targets,\n",
    "                                                   keep_prob,\n",
    "                                                   batch_size,\n",
    "                                                   target_sequence_length,\n",
    "                                                   max_target_sequence_length,\n",
    "                                                   len(source_vocab_to_int),\n",
    "                                                   len(target_vocab_to_int),\n",
    "                                                   encoding_embedding_size,\n",
    "                                                   decoding_embedding_size,\n",
    "                                                   rnn_size,\n",
    "                                                   num_layers,\n",
    "                                                   target_vocab_to_int)\n",
    "    \n",
    "    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/sequence_mask\n",
    "    # - Returns a mask tensor representing the first N positions of each cell.\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function - weighted softmax cross entropy\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        \n",
    "        \n",
    "        '''tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),max_grad_norm)'''\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "\n",
    "        # Slice the right amount for the batch\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "\n",
    "        # Pad\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "\n",
    "        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and validation sets\n",
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "valid_source = source_int_text[:batch_size]\n",
    "valid_target = target_int_text[:batch_size]\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths ) = next(get_batches(valid_source,\n",
    "                                                                                                             valid_target,\n",
    "                                                                                                             batch_size,\n",
    "                                                                                                             source_vocab_to_int['<PAD>'],\n",
    "                                                                                                             target_vocab_to_int['<PAD>']))               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch   30/156 - Train Accuracy: 0.3229, Validation Accuracy: 0.4844, Loss: 4.4645\n",
      "Epoch   0 Batch   60/156 - Train Accuracy: 0.2578, Validation Accuracy: 0.4844, Loss: 4.4948\n",
      "Epoch   0 Batch   90/156 - Train Accuracy: 0.3571, Validation Accuracy: 0.4844, Loss: 3.9553\n",
      "Epoch   0 Batch  120/156 - Train Accuracy: 0.5020, Validation Accuracy: 0.5339, Loss: 3.5857\n",
      "Epoch   0 Batch  150/156 - Train Accuracy: 0.3504, Validation Accuracy: 0.5651, Loss: 4.2503\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    \n",
    "    loss_track=[]\n",
    "    grad_track = []\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "                get_batches(train_source, train_target, batch_size,\n",
    "                            source_vocab_to_int['<PAD>'],\n",
    "                            target_vocab_to_int['<PAD>'])):\n",
    "\n",
    "            #print(target_batch)\n",
    "            #print(epoch_i)\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "            loss_track.append(loss)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                batch_train_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: source_batch,\n",
    "                     target_sequence_length: targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                batch_valid_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: valid_sources_batch,\n",
    "                     target_sequence_length: valid_targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "                valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)\n",
    "\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n",
    "                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)               \n",
    "                \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1db849e8>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_params(params):\n",
    "    with open('params-du-en-bi.p', 'wb') as out_file:\n",
    "        pickle.dump(params, out_file)\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    with open('params-du-en-bi.p', mode='rb') as in_file:\n",
    "        return pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/ayan\n",
      "Input\n",
      "  Word Ids:      [1069, 1197, 1643, 2]\n",
      "  English Words: ['how', 'are', 'you', '<UNK>']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [1526, 1526, 1]\n",
      "  German Words: ich ich <EOS>\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    results = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in vocab_to_int:\n",
    "            results.append(vocab_to_int[word])\n",
    "        else:\n",
    "            results.append(vocab_to_int['<UNK>'])\n",
    "            \n",
    "    return results\n",
    "\n",
    "translate_sentence = 'how are you today?'\n",
    "\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,\n",
    "                                         target_sequence_length: [len(translate_sentence)*2]*batch_size,\n",
    "                                         keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_logits]))\n",
    "print('  German Words: {}'.format(\" \".join([target_int_to_vocab[i] for i in translate_logits])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
