{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "import collections\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "import sys\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hi.', 'Hallo!'], ['Hi.', 'Grüß Gott!']]\n",
      "['Hi.\\tHallo!', 'Hi.\\tGrüß Gott!']\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "all_lines=[]\n",
    "\n",
    "fptr = open('deu.txt', 'r', encoding='utf-8')\n",
    "# read all text\n",
    "lines = fptr.readlines()\n",
    "#print(lines)\n",
    "for line in lines :\n",
    "    #print(line)\n",
    "    line=line.strip()\n",
    "    k = line.split('\\t')\n",
    "    \n",
    "    all_lines.append(line)\n",
    "    pairs.append(k)\n",
    "print(pairs[0:2])\n",
    "print(all_lines[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng_length = 0\n",
    "max_ger_length = 0\n",
    "\n",
    "cleaned = list()\n",
    "# prepare regex for char filtering\n",
    "re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "# prepare translation table for removing punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for pair in pairs:\n",
    "    #print(pair[0])\n",
    "    \n",
    "        \n",
    "    clean_pair = list()\n",
    "    for line in pair:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "        # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        # store as string\n",
    "        clean_pair.append(' '.join(line))\n",
    "    cleaned.append(clean_pair)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi => hallo\n",
      "hi => gru gott\n"
     ]
    }
   ],
   "source": [
    "print(cleaned[0][0] + \" => \" + cleaned[0][1])\n",
    "print(cleaned[1][0] + \" => \" + cleaned[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi', 'hallo'], ['hi', 'gru gott']]\n",
      "10000\n",
      "['hi', 'hallo']\n",
      "['hi', 'gru gott']\n"
     ]
    }
   ],
   "source": [
    "# reduce dataset size\n",
    "n_sentences = 10000\n",
    "dataset = cleaned[:n_sentences]\n",
    "print(dataset[0:2])\n",
    "print(len(dataset))\n",
    "print(dataset[0:2][0])\n",
    "print(dataset[0:2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'hallo']\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "max_eng_length = 0\n",
    "max_ger_length = 0\n",
    "\n",
    "for i in range(len(dataset)) :\n",
    "    if(len(dataset[i][0]) > max_eng_length) :\n",
    "        max_eng_length = len(dataset[i][0])\n",
    "    if(len(dataset[i][1]) > max_ger_length) :\n",
    "        max_ger_length = len(dataset[i][1])\n",
    "        \n",
    "print(max_eng_length)\n",
    "print(max_ger_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "gru gott\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for i in range(len(dataset)) :\n",
    "    questions.append(dataset[i][0])\n",
    "    labels.append(dataset[i][1])\n",
    "print(questions[1])\n",
    "print(labels[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_data(que, lab):\n",
    "    # Preprocess\n",
    "    qs = []\n",
    "    lb = []\n",
    "\n",
    "    # to the lower case\n",
    "    for i in que :\n",
    "        i=i.lower()\n",
    "        qs.append(i)\n",
    "    for j in lab :\n",
    "        j=j.lower()\n",
    "        lb.append(j)\n",
    "\n",
    "    # create lookup tables for English and French data\n",
    "    CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "    source_vocab = []\n",
    "    target_vocab = []\n",
    "    \n",
    "    for q in qs :\n",
    "        for j in q.split() :\n",
    "            source_vocab.append(j)\n",
    "            \n",
    "    source_vocab = set(source_vocab)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for l in lb :\n",
    "        for k in l.split() :\n",
    "            target_vocab.append(k)\n",
    "            \n",
    "    target_vocab = set(target_vocab)\n",
    "    #print(target_vocab)\n",
    "    \n",
    "    source_vocab_to_int = copy.copy(CODES)\n",
    "    for v_i, v in enumerate(source_vocab, len(CODES)):\n",
    "        source_vocab_to_int[v] = v_i\n",
    "\n",
    "\n",
    "    source_int_to_vocab = {v_i: v for v, v_i in source_vocab_to_int.items()}    \n",
    "    \n",
    "\n",
    " \n",
    "    target_vocab_to_int = copy.copy(CODES)\n",
    "    for v_i, v in enumerate(target_vocab, len(CODES)):\n",
    "        target_vocab_to_int[v] = v_i\n",
    "\n",
    "\n",
    "    target_int_to_vocab = {v_i: v for v, v_i in target_vocab_to_int.items()}\n",
    "    \n",
    "    \n",
    "\n",
    "    # create list of sentences whose words are represented in index\n",
    "    \n",
    "    source_text = []\n",
    "    target_text = []\n",
    "    \n",
    "    for q in qs :\n",
    "        source_tokens = q.split(\" \")\n",
    "        \n",
    "        # empty list of converted words to index in the chosen sentence\n",
    "        source_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(source_tokens):\n",
    "            if (token != \"\"):\n",
    "                source_token_id.append(source_vocab_to_int[token])\n",
    "\n",
    "        source_text.append(source_token_id)        \n",
    "\n",
    "    for l in lb :\n",
    "        target_tokens = l.split(\" \")\n",
    "        \n",
    "        # empty list of converted words to index in the chosen sentence\n",
    "        target_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(target_tokens):\n",
    "            if (token != \"\"):\n",
    "                target_token_id.append(target_vocab_to_int[token])\n",
    "       \n",
    "                \n",
    "        # put <EOS> token at the end of the chosen target sentence\n",
    "        # this token suggests when to stop creating a sequence\n",
    "        target_token_id.append(target_vocab_to_int['<EOS>'])        \n",
    "        \n",
    "        target_text.append(target_token_id) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (source_text, target_text),(source_vocab_to_int, target_vocab_to_int),(source_int_to_vocab, target_int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[674], [674]]\n",
      "[[565, 1], [3503, 2433, 1]]\n"
     ]
    }
   ],
   "source": [
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab,target_int_to_vocab) = preprocess_and_save_data(questions,labels)\n",
    "\n",
    "print(source_int_text[0:2])\n",
    "print(target_int_text[0:2])\n",
    "#print(target_int_to_vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec_model_inputs():\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets') \n",
    "    \n",
    "    target_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n",
    "    max_target_len = tf.reduce_max(target_sequence_length)    \n",
    "    \n",
    "    return inputs, targets, target_sequence_length, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_inputs():\n",
    "    lr_rate = tf.placeholder(tf.float32, name='lr_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return lr_rate, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_decoder_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for encoding\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    # get '<GO>' id\n",
    "    go_id = target_vocab_to_int['<GO>']\n",
    "    \n",
    "    after_slice = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    after_concat = tf.concat( [tf.fill([batch_size, 1], go_id), after_slice], 1)\n",
    "    \n",
    "    return after_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, \n",
    "                   source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "    \"\"\"\n",
    "    :return: tuple (RNN output, RNN state)\n",
    "    \"\"\"\n",
    "    embed = tf.contrib.layers.embed_sequence(rnn_inputs, \n",
    "                                             vocab_size=source_vocab_size, \n",
    "                                             embed_dim=encoding_embedding_size)\n",
    "    \n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(rnn_size), keep_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    outputs, state = tf.nn.dynamic_rnn(stacked_cells, \n",
    "                                       embed, \n",
    "                                       dtype=tf.float32)\n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, \n",
    "                         target_sequence_length, max_summary_length, \n",
    "                         output_layer, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a training process in decoding layer \n",
    "    :return: BasicDecoderOutput containing training logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "    \n",
    "    # for only input layer\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input, \n",
    "                                               target_sequence_length)\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, \n",
    "                                              helper, \n",
    "                                              encoder_state, \n",
    "                                              output_layer)\n",
    "\n",
    "    # unrolling the decoder layer\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True, \n",
    "                                                      maximum_iterations=max_summary_length)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id,\n",
    "                         end_of_sequence_id, max_target_sequence_length,\n",
    "                         vocab_size, output_layer, batch_size, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a inference process in decoding layer \n",
    "    :return: BasicDecoderOutput containing inference logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings, \n",
    "                                                      tf.fill([batch_size], start_of_sequence_id), \n",
    "                                                      end_of_sequence_id)\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, \n",
    "                                              helper, \n",
    "                                              encoder_state, \n",
    "                                              output_layer)\n",
    "    \n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True, \n",
    "                                                      maximum_iterations=max_target_sequence_length)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer(dec_input, encoder_state,\n",
    "                   target_sequence_length, max_target_sequence_length,\n",
    "                   rnn_size,\n",
    "                   num_layers, target_vocab_to_int, target_vocab_size,\n",
    "                   batch_size, keep_prob, decoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    target_vocab_size = len(target_vocab_to_int)\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "    \n",
    "    cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        output_layer = tf.layers.Dense(target_vocab_size)\n",
    "        train_output = decoding_layer_train(encoder_state, \n",
    "                                            cells, \n",
    "                                            dec_embed_input, \n",
    "                                            target_sequence_length, \n",
    "                                            max_target_sequence_length, \n",
    "                                            output_layer, \n",
    "                                            keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        infer_output = decoding_layer_infer(encoder_state, \n",
    "                                            cells, \n",
    "                                            dec_embeddings, \n",
    "                                            target_vocab_to_int['<GO>'], \n",
    "                                            target_vocab_to_int['<EOS>'], \n",
    "                                            max_target_sequence_length, \n",
    "                                            target_vocab_size, \n",
    "                                            output_layer,\n",
    "                                            batch_size,\n",
    "                                            keep_prob)\n",
    "\n",
    "    return (train_output, infer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n",
    "                  target_sequence_length,\n",
    "                  max_target_sentence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size,\n",
    "                  rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence model\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    enc_outputs, enc_states = encoding_layer(input_data, \n",
    "                                             rnn_size, \n",
    "                                             num_layers, \n",
    "                                             keep_prob, \n",
    "                                             source_vocab_size, \n",
    "                                             enc_embedding_size)\n",
    "    \n",
    "    dec_input = process_decoder_input(target_data, \n",
    "                                      target_vocab_to_int, \n",
    "                                      batch_size)\n",
    "    \n",
    "    train_output, infer_output = decoding_layer(dec_input,\n",
    "                                               enc_states, \n",
    "                                               target_sequence_length, \n",
    "                                               max_target_sentence_length,\n",
    "                                               rnn_size,\n",
    "                                              num_layers,\n",
    "                                              target_vocab_to_int,\n",
    "                                              target_vocab_size,\n",
    "                                              batch_size,\n",
    "                                              keep_prob,\n",
    "                                              dec_embedding_size)\n",
    "    \n",
    "    return train_output, infer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_step = 30\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "\n",
    "rnn_size = 128\n",
    "num_layers = 3\n",
    "\n",
    "encoding_embedding_size = 100\n",
    "decoding_embedding_size = 100\n",
    "\n",
    "learning_rate = 0.001\n",
    "keep_probability = 0.5\n",
    "max_grad_norm = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'checkpoints/ayan'\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab,target_int_to_vocab) = preprocess_and_save_data(questions,labels)\n",
    "max_target_sentence_length = max([len(sentence) for sentence in source_int_text])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, target_sequence_length, max_target_sequence_length = enc_dec_model_inputs()\n",
    "    lr, keep_prob = hyperparam_inputs()\n",
    "    \n",
    "    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                   targets,\n",
    "                                                   keep_prob,\n",
    "                                                   batch_size,\n",
    "                                                   target_sequence_length,\n",
    "                                                   max_target_sequence_length,\n",
    "                                                   len(source_vocab_to_int),\n",
    "                                                   len(target_vocab_to_int),\n",
    "                                                   encoding_embedding_size,\n",
    "                                                   decoding_embedding_size,\n",
    "                                                   rnn_size,\n",
    "                                                   num_layers,\n",
    "                                                   target_vocab_to_int)\n",
    "    \n",
    "    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/sequence_mask\n",
    "    # - Returns a mask tensor representing the first N positions of each cell.\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function - weighted softmax cross entropy\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        \n",
    "        \n",
    "        '''tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),max_grad_norm)'''\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "\n",
    "        # Slice the right amount for the batch\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "\n",
    "        # Pad\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "\n",
    "        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and validation sets\n",
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "valid_source = source_int_text[:batch_size]\n",
    "valid_target = target_int_text[:batch_size]\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths ) = next(get_batches(valid_source,\n",
    "                                                                                                             valid_target,\n",
    "                                                                                                             batch_size,\n",
    "                                                                                                             source_vocab_to_int['<PAD>'],\n",
    "                                                                                                             target_vocab_to_int['<PAD>']))               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch   30/156 - Train Accuracy: 0.3229, Validation Accuracy: 0.4844, Loss: 4.4365\n",
      "Epoch   0 Batch   60/156 - Train Accuracy: 0.2578, Validation Accuracy: 0.4844, Loss: 4.6598\n",
      "Epoch   0 Batch   90/156 - Train Accuracy: 0.3103, Validation Accuracy: 0.4844, Loss: 4.1350\n",
      "Epoch   0 Batch  120/156 - Train Accuracy: 0.4160, Validation Accuracy: 0.4844, Loss: 3.6376\n",
      "Epoch   0 Batch  150/156 - Train Accuracy: 0.3504, Validation Accuracy: 0.4844, Loss: 4.2880\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    \n",
    "    loss_track=[]\n",
    "    grad_track = []\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "                get_batches(train_source, train_target, batch_size,\n",
    "                            source_vocab_to_int['<PAD>'],\n",
    "                            target_vocab_to_int['<PAD>'])):\n",
    "\n",
    "            #print(target_batch)\n",
    "            #print(epoch_i)\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "            loss_track.append(loss)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                batch_train_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: source_batch,\n",
    "                     target_sequence_length: targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                batch_valid_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: valid_sources_batch,\n",
    "                     target_sequence_length: valid_targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "                valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)\n",
    "\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n",
    "                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)               \n",
    "                \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e8a08d0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_params(params):\n",
    "    with open('params-du.p', 'wb') as out_file:\n",
    "        pickle.dump(params, out_file)\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    with open('params-du.p', mode='rb') as in_file:\n",
    "        return pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/ayan\n",
      "Input\n",
      "  Word Ids:      [1789, 1308, 1813, 2]\n",
      "  English Words: ['how', 'are', 'you', '<UNK>']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [1093, 1093, 1]\n",
      "  German Words: ich ich <EOS>\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    results = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in vocab_to_int:\n",
    "            results.append(vocab_to_int[word])\n",
    "        else:\n",
    "            results.append(vocab_to_int['<UNK>'])\n",
    "            \n",
    "    return results\n",
    "\n",
    "translate_sentence = 'how are you today?'\n",
    "\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,\n",
    "                                         target_sequence_length: [len(translate_sentence)*2]*batch_size,\n",
    "                                         keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_logits]))\n",
    "print('  German Words: {}'.format(\" \".join([target_int_to_vocab[i] for i in translate_logits])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
